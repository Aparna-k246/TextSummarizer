# ğŸ§¾ TextSummarizer â€” End-to-End NLP Project with MLOps + APIs + Hugging Face ğŸ¤—

A complete end-to-end **Text Summarization** ML pipeline using ğŸ§  Transformer models (Pegasus), ğŸ§° MLOps principles, and ğŸ›°ï¸ API deployment.

---

## ğŸš€ Features

- ğŸ“¦ Data Ingestion (local/file-based)
- ğŸ”§ Data Transformation (tokenization, formatting)
- ğŸ§  Model Training (Pegasus from Hugging Face ğŸ¤—)
- ğŸ§ª Model Evaluation (BLEU/Rouge)
- ğŸ› ï¸ Training + Prediction Pipelines
- ğŸŒ REST API with FastAPI
- ğŸ³ Dockerized
- â˜ï¸ Workflow Automation (CI/CD ready)
- ğŸ“Š Frontend-ready structure

---

## ğŸ”„ Workflows

CI/CD & automation enabled via GitHub Actions:

```bash
.github/workflows/
â””â”€â”€ main.yaml  # ğŸ” Auto tests + linting
```

---

## âš™ï¸ Configuration Files

```bash
config/
â”œâ”€â”€ config.yaml         # âœ… Central project config (paths, dirs)
params.yaml             # âš™ï¸ Hyperparameters (epochs, batch_size, etc.)
```

---

## ğŸ“¦ Configuration Entity & Manager

- `ModelTrainerConfig`, `DataIngestionConfig`, etc. defined in ğŸ§  `textSummarizer.entity`
- `ConfigurationManager` reads YAML and prepares configs dynamically

---

## ğŸ§© Components

Modularized under `textSummarizer/components/`:

- ğŸ“¥ `data_ingestion.py`
- ğŸ§½ `data_transformation.py`
- ğŸ¤– `model_trainer.py`
- ğŸ“ˆ `model_evaluation.py`

---

## ğŸ§¬ Training & Prediction Pipelines

```bash
src/textSummarizer/pipeline/
â”œâ”€â”€ stage_1_data_ingestion_pipeline.py
â”œâ”€â”€ stage_2_data_transformation_pipeline.py
â”œâ”€â”€ stage_3_model_trainer_pipeline.py
â”œâ”€â”€ stage_4_model_evaluation.py
â”œâ”€â”€ prediction_pipeline.py
```

---

## ğŸŒ Frontend & API Support

- `main.py` â€” Main FastAPI app
- `app.py` â€” Entry point for web interface
- API endpoints:
  - ğŸ‹ï¸ `/train` â†’ triggers training pipeline
  - ğŸ”® `/predict` â†’ summary prediction
  - ğŸ“‚ `/batch_predict` â†’ batch inference

---

## ğŸ¤— Powered by Hugging Face Transformers

This project uses the ğŸ¤— [Hugging Face Transformers](https://huggingface.co/docs/transformers/index) library with:

- `AutoModelForSeq2SeqLM` â€“ loads Pegasus
- `AutoTokenizer` â€“ tokenizer for Pegasus
- ğŸ“¦ Model checkpoint: `google/pegasus-cnn_dailymail`

---

## ğŸ“ Folder Structure

```bash
.
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ main.yaml
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ src/textSummarizer/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ constants/
â”‚   â”œâ”€â”€ entity/
â”‚   â”œâ”€â”€ logging/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”œâ”€â”€ utils/
â”œâ”€â”€ research/                         # ğŸ“Š Jupyter notebooks
â”œâ”€â”€ app.py                            # ğŸŒ FastAPI UI
â”œâ”€â”€ main.py                           # ğŸš€ FastAPI runner
â”œâ”€â”€ params.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â””â”€â”€ README.md
```

---

## ğŸ§ª How to Run

1. ğŸ”¨ Install dependencies:

```bash
pip install -r requirements.txt
```

2. ğŸš€ Train the model:

```bash
python main.py
```

3. ğŸŒ Run the API locally:

```bash
uvicorn app:app --reload
```

4. ğŸ³ (Optional) Run with Docker:

```bash
docker build -t textsummarizer .
docker run -p 8080:8080 textsummarizer
```

---

## ğŸ§‘â€ğŸ’¼ For Recruiters

This project demonstrates real-world end-to-end skills:

âœ… Clean modular code with separation of concerns  
âœ… MLOps principles (configs, pipelines, automation)  
âœ… Hugging Face ğŸ¤— integration for production NLP  
âœ… FastAPI backend with custom endpoints  
âœ… Docker support for containerized deployment  
âœ… CI-ready structure for scalable development  
âœ… Project structure that reflects production readiness  

Please feel free to reach out for walkthroughs or codebase clarity!

---

## ğŸ“Œ To-Do

- [ ] Add Streamlit frontend
- [ ] Add monitoring/alerts (Prometheus/Grafana)
- [ ] Add model versioning with MLflow

---

## ğŸ“„ License

[MIT License](LICENSE)

---

## âœ¨ Star this repo if it helped you!
